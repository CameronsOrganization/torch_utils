{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jax'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtu\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexperiment_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01meu\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjaxtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Num, Array\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/torch_utils/.venv/lib/python3.12/site-packages/jaxtyping/__init__.py:183\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(item)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;129m@ft\u001b[39m.cache\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(item):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m item == \u001b[33m\"\u001b[39m\u001b[33mArray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m jax.Array\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m item == \u001b[33m\"\u001b[39m\u001b[33mArrayLike\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'jax'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import datasets\n",
    "import transformers\n",
    "import torch_utils as tu\n",
    "import experiment_utils as eu\n",
    "from jaxtyping import Num, Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "batch_size = 16\n",
    "lr = 1e-3\n",
    "train_steps = 5000\n",
    "val_steps = 1000\n",
    "log_steps = 100\n",
    "warmup_steps = train_steps // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"karpathy/tiny_shakespeare\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6009f97098042d88446dea6a516c674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45f9269e5c043baaa151f3abb9b7e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc7cb647de546cda6e5a6ea0a2f9940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer: transformers.PreTrainedTokenizerFast = (\n",
    "    transformers.AutoTokenizer.from_pretrained(\"../tokenizers/bytelevel\")\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    outputs = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        max_length=seq_len + 1,\n",
    "        stride=1,\n",
    "        truncation=True,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "\n",
    "    input_ids = []\n",
    "    target_ids = []\n",
    "    for length, ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length - 1 == seq_len:\n",
    "            input_ids.append(ids[:-1])\n",
    "            target_ids.append(ids[1:])\n",
    "    return {\"input_ids\": input_ids, \"target_ids\": target_ids}\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DefaultDataCollator()\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    tokenized_dataset[\"validation\"],\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    tokenized_dataset[\"test\"],\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper(nn.Module):\n",
    "    metrics = {\"perplexity\": eu.compare_fns.min}\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Llama()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        target_ids = batch[\"target_ids\"].view(-1)\n",
    "        output_logits = self.model(input_ids).view(-1, input_ids.size(-1))\n",
    "\n",
    "        loss = nn.functional.cross_entropy(output_logits, target_ids)\n",
    "        ppl = torch.exp(loss)\n",
    "\n",
    "        output = {\n",
    "            \"output_logits\": output_logits,\n",
    "            \"loss\": loss,\n",
    "            \"perplexity\": ppl,\n",
    "        }\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = tu.get_lr_scheduler(optimizer, train_steps, warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = eu.Logger(\"../.logs/llm\")\n",
    "logger.start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    train_steps=train_steps,\n",
    "    logger=logger,\n",
    "    log_steps=log_steps,\n",
    "    val_steps=val_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.end_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
